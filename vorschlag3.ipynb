{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        product_name  \\\n",
      "0  The Ordinary Natural Moisturising Factors + HA...   \n",
      "1      CeraVe Facial Moisturising Lotion SPF 25 52ml   \n",
      "2  The Ordinary Hyaluronic Acid 2% + B5 Hydration...   \n",
      "3          AMELIORATE Transforming Body Lotion 200ml   \n",
      "4                     CeraVe Moisturising Cream 454g   \n",
      "\n",
      "                                         product_url product_type  \\\n",
      "0  https://www.lookfantastic.com/the-ordinary-nat...  Moisturiser   \n",
      "1  https://www.lookfantastic.com/cerave-facial-mo...  Moisturiser   \n",
      "2  https://www.lookfantastic.com/the-ordinary-hya...  Moisturiser   \n",
      "3  https://www.lookfantastic.com/ameliorate-trans...  Moisturiser   \n",
      "4  https://www.lookfantastic.com/cerave-moisturis...  Moisturiser   \n",
      "\n",
      "                                         ingredients   price  \n",
      "0  Aqua (Water), Caprylic/Capric Triglyceride, Ce...   £5.20  \n",
      "1  Aqua/Water, Homosalate, Glycerin, Octocrylene,...  £13.00  \n",
      "2  Aqua (Water), Sodium Hyaluronate, Sodium Hyalu...   £6.20  \n",
      "3  Aqua/Water/Eau, Ammonium Lactate, C12-15 Alkyl...  £22.50  \n",
      "4  Purified Water, Glycerin, Ceteareth-20 and Cet...  £16.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Daten laden\n",
    "url = \"skincare_products.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Erste Zeilen anzeigen, um die Daten zu überprüfen\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [aquawater, capryliccaprictriglyceride, cetyla...\n",
      "1    [aquawater, homosalate, glycerin, octocrylene,...\n",
      "2    [aquawater, sodiumhyaluronate, sodiumhyalurona...\n",
      "3    [aquawatereau, ammoniumlactate, calkylbenzoate...\n",
      "4    [purifiedwater, glycerin, cetearethandcetearyl...\n",
      "Name: processed_ingredients, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#textvorverarbeitung\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_ingredients(text):\n",
    "    text = text.lower()  # in Kleinbuchstaben umwandeln\n",
    "    text = re.sub(r'[^a-z,]', '', text)  # Nicht-Buchstaben entfernen, außer Kommas\n",
    "    ingredients = text.split(\",\")  # Bei Kommas trennen\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredients]  # Leerzeichen entfernen\n",
    "    return ingredients\n",
    "\n",
    "df['processed_ingredients'] = df['ingredients'].apply(preprocess_ingredients)\n",
    "print(df['processed_ingredients'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get embeddings for a batch of text\n",
    "def get_embeddings(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    return output.pooler_output.squeeze().numpy()\n",
    "\n",
    "# Applying the function on the concatenated ingredient text\n",
    "df['ingredient_text'] = df['processed_ingredients'].apply(lambda x: ', '.join(x))\n",
    "df['embeddings'] = df['ingredient_text'].apply(get_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          product_name  \\\n",
      "7    The Ordinary Natural Moisturizing Factors + HA...   \n",
      "44               Skin Doctors Sd White & Bright (50ml)   \n",
      "122               The Ordinary Marine Hyaluronics 30ml   \n",
      "355    Zelens PROVITAMIN D Fortifying Facial Mist 50ml   \n",
      "223       Elizabeth Arden Prevage Advanced Daily Serum   \n",
      "210                      Indeed Labs Pepta-Bright 30ml   \n",
      "390  La Roche-Posay Cicaplast Baume B5 Repairing Ba...   \n",
      "667  Estée Lauder Resilience Multi-Effect Tri-Pepti...   \n",
      "622  Fade Out Advanced Even Skin Tone Eye Defence C...   \n",
      "680        SkinCeuticals A.G.E. Eye Complex Cream 15ml   \n",
      "\n",
      "                                           product_url product_type  \n",
      "7    https://www.lookfantastic.com/the-ordinary-nat...  Moisturiser  \n",
      "44   https://www.lookfantastic.com/skin-doctors-sd-...  Moisturiser  \n",
      "122  https://www.lookfantastic.com/the-ordinary-mar...        Serum  \n",
      "355  https://www.lookfantastic.com/zelens-provitami...         Mist  \n",
      "223  https://www.lookfantastic.com/elizabeth-arden-...        Serum  \n",
      "210  https://www.lookfantastic.com/indeed-labs-pept...        Serum  \n",
      "390  https://www.lookfantastic.com/la-roche-posay-c...         Balm  \n",
      "667  https://www.lookfantastic.com/estee-lauder-res...     Eye Care  \n",
      "622  https://www.lookfantastic.com/fade-out-advance...     Eye Care  \n",
      "680  https://www.lookfantastic.com/skinceuticals-a....     Eye Care  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming embeddings are stored as a list of numpy arrays\n",
    "embeddings = np.stack(df['embeddings'].values)\n",
    "cosine_sim = cosine_similarity(embeddings)\n",
    "\n",
    "def enhanced_recommend_products(product_name, df, cosine_sim, top_k=10):\n",
    "    idx = df[df['product_name'] == product_name].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    product_indices = [i[0] for i in sim_scores[1:top_k+1]]\n",
    "    return df.loc[product_indices, ['product_name', 'product_url', 'product_type']]\n",
    "\n",
    "# Test the enhanced recommendation function\n",
    "print(enhanced_recommend_products(\"The Ordinary Natural Moisturising Factors + HA 30ml\", df, cosine_sim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/43.8 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 30.7/43.8 kB 217.9 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 41.0/43.8 kB 245.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.8/43.8 kB 238.1 kB/s eta 0:00:00\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from transformers) (24.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading typing_extensions-4.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Downloading tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.1 MB 20.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.6/9.1 MB 38.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/9.1 MB 42.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.6/9.1 MB 49.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 44.7 MB/s eta 0:00:00\n",
      "Downloading torch-2.3.0-cp312-cp312-win_amd64.whl (159.7 MB)\n",
      "   ---------------------------------------- 0.0/159.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.9/159.7 MB 62.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 5.0/159.7 MB 63.7 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 8.4/159.7 MB 67.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 10.9/159.7 MB 59.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 13.6/159.7 MB 59.8 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 16.4/159.7 MB 59.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 19.7/159.7 MB 59.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 22.5/159.7 MB 59.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 24.9/159.7 MB 54.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 26.2/159.7 MB 50.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 30.1/159.7 MB 54.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 32.8/159.7 MB 59.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 35.5/159.7 MB 65.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 38.0/159.7 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 40.4/159.7 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 43.6/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 45.9/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 48.3/159.7 MB 54.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 51.2/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 53.2/159.7 MB 50.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 56.4/159.7 MB 54.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 58.9/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 61.8/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 64.9/159.7 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 68.0/159.7 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 70.1/159.7 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 73.4/159.7 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 73.9/159.7 MB 65.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 74.9/159.7 MB 43.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 76.6/159.7 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 79.2/159.7 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.1/159.7 MB 38.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 84.0/159.7 MB 38.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 86.7/159.7 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 88.1/159.7 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 88.1/159.7 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 88.1/159.7 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 89.3/159.7 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 92.2/159.7 MB 32.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.0/159.7 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 98.2/159.7 MB 34.4 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 100.6/159.7 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------- ------------- 103.5/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 106.6/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 108.8/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 111.4/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 114.3/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 117.1/159.7 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 120.1/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 123.0/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 125.3/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 127.4/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 130.1/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 133.0/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 135.5/159.7 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 136.7/159.7 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 139.9/159.7 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 142.7/159.7 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 146.0/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 149.4/159.7 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 151.8/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 154.5/159.7 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  156.4/159.7 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.3/159.7 MB 50.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 159.7/159.7 MB 18.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 401.7/401.7 kB 26.1 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 316.1/316.1 kB 19.1 MB/s eta 0:00:00\n",
      "Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "   ---------------------------------------- 0.0/228.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/228.5 MB 80.9 MB/s eta 0:00:03\n",
      "    --------------------------------------- 4.8/228.5 MB 61.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 7.6/228.5 MB 60.5 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 10.7/228.5 MB 59.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 13.3/228.5 MB 59.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 15.6/228.5 MB 65.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 18.1/228.5 MB 59.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 20.8/228.5 MB 59.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 23.7/228.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 26.7/228.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 29.7/228.5 MB 59.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 33.1/228.5 MB 73.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 35.1/228.5 MB 59.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 37.7/228.5 MB 54.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 40.3/228.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 42.1/228.5 MB 54.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 44.9/228.5 MB 54.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 47.7/228.5 MB 54.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 50.3/228.5 MB 54.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 53.2/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 55.1/228.5 MB 59.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 57.5/228.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 60.3/228.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 63.5/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 66.3/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 69.0/228.5 MB 73.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 71.7/228.5 MB 72.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 74.8/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 78.1/228.5 MB 59.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 80.2/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 83.8/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 86.8/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 88.1/228.5 MB 50.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 91.3/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 94.6/228.5 MB 54.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 97.9/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 98.4/228.5 MB 54.7 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 100.6/228.5 MB 50.4 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 102.9/228.5 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 106.8/228.5 MB 50.4 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 108.7/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 111.3/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 114.5/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 117.4/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 119.4/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 120.8/228.5 MB 54.7 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 125.1/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 127.7/228.5 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 131.3/228.5 MB 73.1 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 134.2/228.5 MB 72.6 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 137.0/228.5 MB 73.1 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 140.1/228.5 MB 73.1 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 142.2/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 145.3/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 148.9/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 151.8/228.5 MB 72.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 155.1/228.5 MB 72.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 157.8/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 160.5/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 163.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 166.7/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 169.9/228.5 MB 54.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 172.6/228.5 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 175.8/228.5 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 178.5/228.5 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 181.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 185.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 188.9/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 192.7/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 195.9/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 199.5/228.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 202.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 205.2/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 207.7/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 209.0/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 210.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 213.2/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 217.9/228.5 MB 54.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 221.8/228.5 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  224.7/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  227.6/228.5 MB 73.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 228.5/228.5 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 2.5/3.5 MB 80.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 45.0 MB/s eta 0:00:00\n",
      "Downloading tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.4/286.4 kB ? eta 0:00:00\n",
      "Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 268.5/268.5 kB 16.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp312-none-win_amd64.whl (289 kB)\n",
      "   ---------------------------------------- 0.0/289.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 289.4/289.4 kB 18.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.2/2.2 MB 37.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n",
      "Downloading typing_extensions-4.12.1-py3-none-any.whl (37 kB)\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 54.6 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 3.5/5.7 MB 73.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.7/5.7 MB 73.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 61.0 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 164.4/164.4 kB ? eta 0:00:00\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, urllib3, typing-extensions, tqdm, sympy, safetensors, regex, pyyaml, networkx, mkl, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed MarkupSafe-2.1.5 certifi-2024.6.2 charset-normalizer-3.3.2 filelock-3.14.0 fsspec-2024.5.0 huggingface-hub-0.23.2 idna-3.7 intel-openmp-2021.4.0 jinja2-3.1.4 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.3 safetensors-0.4.3 sympy-1.12.1 tbb-2021.12.0 tokenizers-0.19.1 torch-2.3.0 tqdm-4.66.4 transformers-4.41.2 typing-extensions-4.12.1 urllib3-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers and Torch have been successfully installed.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "print(\"Transformers and Torch have been successfully installed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached scikit_learn-1.5.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.0-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sentence-transformers) (4.41.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sentence-transformers) (0.23.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "                                        product_name  \\\n",
      "0  The Ordinary Natural Moisturising Factors + HA...   \n",
      "1      CeraVe Facial Moisturising Lotion SPF 25 52ml   \n",
      "2  The Ordinary Hyaluronic Acid 2% + B5 Hydration...   \n",
      "3          AMELIORATE Transforming Body Lotion 200ml   \n",
      "4                     CeraVe Moisturising Cream 454g   \n",
      "\n",
      "                                         product_url product_type  \\\n",
      "0  https://www.lookfantastic.com/the-ordinary-nat...  Moisturiser   \n",
      "1  https://www.lookfantastic.com/cerave-facial-mo...  Moisturiser   \n",
      "2  https://www.lookfantastic.com/the-ordinary-hya...  Moisturiser   \n",
      "3  https://www.lookfantastic.com/ameliorate-trans...  Moisturiser   \n",
      "4  https://www.lookfantastic.com/cerave-moisturis...  Moisturiser   \n",
      "\n",
      "                                         ingredients   price  \n",
      "0  Aqua (Water), Caprylic/Capric Triglyceride, Ce...   £5.20  \n",
      "1  Aqua/Water, Homosalate, Glycerin, Octocrylene,...  £13.00  \n",
      "2  Aqua (Water), Sodium Hyaluronate, Sodium Hyalu...   £6.20  \n",
      "3  Aqua/Water/Eau, Ammonium Lactate, C12-15 Alkyl...  £22.50  \n",
      "4  Purified Water, Glycerin, Ceteareth-20 and Cet...  £16.00  \n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Daten laden\n",
    "url = \"skincare_products.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Erste Zeilen anzeigen, um die Daten zu überprüfen\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Vorverarbeitung der Inhaltsstoffe\n",
    "def preprocess_ingredients(text):\n",
    "    text = text.lower()  # In Kleinbuchstaben umwandeln\n",
    "    text = re.sub(r'[^a-z,]', '', text)  # Nicht-Buchstaben entfernen, außer Kommas\n",
    "    ingredients = text.split(\",\")  # Bei Kommas trennen\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredients]  # Leerzeichen entfernen\n",
    "    return ingredients\n",
    "\n",
    "df['processed_ingredients'] = df['ingredients'].apply(preprocess_ingredients)\n",
    "df['ingredient_text'] = df['processed_ingredients'].apply(lambda x: ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\goern_y\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\goern_y\\.pyenv\\pyenv-win\\versions\\3.12.1\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Modell laden (aus tokens_and_embeddings.ipynb)\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Funktion zur Berechnung der Embeddings (aus tokens_and_embeddings.ipynb)\n",
    "def get_embeddings(text):\n",
    "    return model.encode(text, show_progress_bar=False)\n",
    "\n",
    "df['embeddings'] = df['ingredient_text'].apply(get_embeddings)\n",
    "\n",
    "# Cosine Similarity berechnen (aus tokens_and_embeddings.ipynb)\n",
    "embeddings = np.stack(df['embeddings'].values)\n",
    "cosine_sim = cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           product_name  \\\n",
      "702                     CeraVe Hydrating Cleanser 473ml   \n",
      "704                CeraVe Foaming Facial Cleanser 473ml   \n",
      "322   Lumene Nordic Hydra [Lähde] Arctic Spring Wate...   \n",
      "5                      CeraVe Moisturising Lotion 473ml   \n",
      "643   Lumene Nordic Hydra [Lähde] Purity Dew Drops H...   \n",
      "98    Fade Out ADVANCED + Age Protection Even Skin T...   \n",
      "705                     CeraVe Smoothing Cleanser 236ml   \n",
      "1007  La Roche-Posay Lipikar Syndet AP(+) Shower Gel...   \n",
      "495   Garnier Moisture Bomb Deep Sea Water & Hyaluro...   \n",
      "1         CeraVe Facial Moisturising Lotion SPF 25 52ml   \n",
      "\n",
      "                                            product_url product_type   price  \\\n",
      "702   https://www.lookfantastic.com/cerave-hydrating...     Cleanser  £15.00   \n",
      "704   https://www.lookfantastic.com/cerave-foaming-f...     Cleanser  £15.00   \n",
      "322   https://www.lookfantastic.com/lumene-nordic-hy...         Mist  £12.00   \n",
      "5     https://www.lookfantastic.com/cerave-moisturis...  Moisturiser  £15.00   \n",
      "643   https://www.lookfantastic.com/lumene-nordic-hy...     Eye Care  £14.90   \n",
      "98    https://www.lookfantastic.com/fade-out-advance...  Moisturiser  £12.99   \n",
      "705   https://www.lookfantastic.com/cerave-smoothing...     Cleanser  £12.00   \n",
      "1007  https://www.lookfantastic.com/la-roche-posay-l...    Body Wash  £16.50   \n",
      "495   https://www.lookfantastic.com/garnier-moisture...         Mask   £2.99   \n",
      "1     https://www.lookfantastic.com/cerave-facial-mo...  Moisturiser  £13.00   \n",
      "\n",
      "      cosine_similarity  \n",
      "702            0.939645  \n",
      "704            0.935473  \n",
      "322            0.934815  \n",
      "5              0.930937  \n",
      "643            0.929698  \n",
      "98             0.925015  \n",
      "705            0.921233  \n",
      "1007           0.916326  \n",
      "495            0.916123  \n",
      "1              0.915280  \n"
     ]
    }
   ],
   "source": [
    "# Erweiterte Empfehlungsfunktion mit Cosine Similarity-Werten\n",
    "def enhanced_recommend_products(product_name, df, cosine_sim, top_k=10):\n",
    "    try:\n",
    "        idx = df[df['product_name'] == product_name].index[0]\n",
    "    except IndexError:\n",
    "        return \"Produktname nicht gefunden.\"\n",
    "\n",
    "    try:\n",
    "        product_price = df.at[idx, 'price']  # Preis des Referenzprodukts\n",
    "    except KeyError:\n",
    "        return \"Spalte 'price' nicht gefunden.\"\n",
    "\n",
    "    # Ähnlichkeitswerte berechnen und sortieren\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Produkte filtern, die günstiger oder gleich teuer sind\n",
    "    filtered_indices = [(i[0], i[1]) for i in sim_scores if df.at[i[0], 'price'] <= product_price and i[0] != idx][:top_k]\n",
    "\n",
    "    # Empfohlene Produkte zurückgeben\n",
    "    recommended_products = df.loc[[i[0] for i in filtered_indices], ['product_name', 'product_url', 'product_type', 'price']]\n",
    "    recommended_products['cosine_similarity'] = [i[1] for i in filtered_indices]\n",
    "\n",
    "    return recommended_products\n",
    "\n",
    "# Test der erweiterten Empfehlungsfunktion\n",
    "print(enhanced_recommend_products(\"The Ordinary Natural Moisturising Factors + HA 30ml\", df, cosine_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           product_name  \\\n",
      "702                     CeraVe Hydrating Cleanser 473ml   \n",
      "704                CeraVe Foaming Facial Cleanser 473ml   \n",
      "322   Lumene Nordic Hydra [Lähde] Arctic Spring Wate...   \n",
      "5                      CeraVe Moisturising Lotion 473ml   \n",
      "643   Lumene Nordic Hydra [Lähde] Purity Dew Drops H...   \n",
      "98    Fade Out ADVANCED + Age Protection Even Skin T...   \n",
      "705                     CeraVe Smoothing Cleanser 236ml   \n",
      "1007  La Roche-Posay Lipikar Syndet AP(+) Shower Gel...   \n",
      "495   Garnier Moisture Bomb Deep Sea Water & Hyaluro...   \n",
      "1         CeraVe Facial Moisturising Lotion SPF 25 52ml   \n",
      "\n",
      "                                            product_url product_type   price  \\\n",
      "702   https://www.lookfantastic.com/cerave-hydrating...     Cleanser  £15.00   \n",
      "704   https://www.lookfantastic.com/cerave-foaming-f...     Cleanser  £15.00   \n",
      "322   https://www.lookfantastic.com/lumene-nordic-hy...         Mist  £12.00   \n",
      "5     https://www.lookfantastic.com/cerave-moisturis...  Moisturiser  £15.00   \n",
      "643   https://www.lookfantastic.com/lumene-nordic-hy...     Eye Care  £14.90   \n",
      "98    https://www.lookfantastic.com/fade-out-advance...  Moisturiser  £12.99   \n",
      "705   https://www.lookfantastic.com/cerave-smoothing...     Cleanser  £12.00   \n",
      "1007  https://www.lookfantastic.com/la-roche-posay-l...    Body Wash  £16.50   \n",
      "495   https://www.lookfantastic.com/garnier-moisture...         Mask   £2.99   \n",
      "1     https://www.lookfantastic.com/cerave-facial-mo...  Moisturiser  £13.00   \n",
      "\n",
      "      cosine_similarity  \n",
      "702            0.939645  \n",
      "704            0.935473  \n",
      "322            0.934815  \n",
      "5              0.930937  \n",
      "643            0.929698  \n",
      "98             0.925015  \n",
      "705            0.921233  \n",
      "1007           0.916326  \n",
      "495            0.916123  \n",
      "1              0.915280  \n"
     ]
    }
   ],
   "source": [
    "#Testbereich Empfehlung ohne Produttyp-Filter\n",
    "\n",
    "print(enhanced_recommend_products(\"The Ordinary Natural Moisturising Factors + HA 30ml\", df, cosine_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          product_name  \\\n",
      "5                     CeraVe Moisturising Lotion 473ml   \n",
      "98   Fade Out ADVANCED + Age Protection Even Skin T...   \n",
      "1        CeraVe Facial Moisturising Lotion SPF 25 52ml   \n",
      "40           La Roche-Posay Nutritic Intense Rich 50ml   \n",
      "58        The INKEY List Multi-Biotic Moisturiser 30ml   \n",
      "72                 Bulldog Sensitive Moisturiser 100ml   \n",
      "6        CeraVe Facial Moisturising Lotion No SPF 52ml   \n",
      "36   La Roche-Posay Effaclar K(+) Anti-Blackhead Mo...   \n",
      "103                        Liz Earle Skin Repair Light   \n",
      "23                  Bulldog Original Moisturiser 100ml   \n",
      "\n",
      "                                           product_url product_type   price  \\\n",
      "5    https://www.lookfantastic.com/cerave-moisturis...  Moisturiser  £15.00   \n",
      "98   https://www.lookfantastic.com/fade-out-advance...  Moisturiser  £12.99   \n",
      "1    https://www.lookfantastic.com/cerave-facial-mo...  Moisturiser  £13.00   \n",
      "40   https://www.lookfantastic.com/la-roche-posay-n...  Moisturiser  £18.00   \n",
      "58   https://www.lookfantastic.com/the-inkey-list-m...  Moisturiser  £12.99   \n",
      "72   https://www.lookfantastic.com/bulldog-sensitiv...  Moisturiser   £4.50   \n",
      "6    https://www.lookfantastic.com/cerave-facial-mo...  Moisturiser  £13.00   \n",
      "36   https://www.lookfantastic.com/la-roche-posay-e...  Moisturiser  £17.00   \n",
      "103  https://www.lookfantastic.com/liz-earle-skin-r...  Moisturiser  £23.00   \n",
      "23   https://www.lookfantastic.com/bulldog-original...  Moisturiser   £4.50   \n",
      "\n",
      "     cosine_similarity  \n",
      "5             0.930937  \n",
      "98            0.925015  \n",
      "1             0.915280  \n",
      "40            0.910145  \n",
      "58            0.910117  \n",
      "72            0.905090  \n",
      "6             0.898729  \n",
      "36            0.895242  \n",
      "103           0.894374  \n",
      "23            0.890928  \n"
     ]
    }
   ],
   "source": [
    "# Erweiterte Empfehlungsfunktion mit Produkttyp- und Cosine Similarity-Filter\n",
    "def enhanced_recommend_products_same_type(product_name, df, cosine_sim, top_k=10):\n",
    "    try:\n",
    "        idx = df[df['product_name'] == product_name].index[0]\n",
    "    except IndexError:\n",
    "        return \"Produktname nicht gefunden.\"\n",
    "\n",
    "    try:\n",
    "        product_price = df.at[idx, 'price']  # Preis des Referenzprodukts\n",
    "        product_type = df.at[idx, 'product_type']  # Produkttyp des Referenzprodukts\n",
    "    except KeyError as e:\n",
    "        return f\"Spalte {e} nicht gefunden.\"\n",
    "\n",
    "    # Ähnlichkeitswerte berechnen und sortieren\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Produkte filtern, die günstiger oder gleich teuer und vom gleichen Produkttyp sind\n",
    "    filtered_indices = [(i[0], i[1]) for i in sim_scores if df.at[i[0], 'price'] <= product_price and df.at[i[0], 'product_type'] == product_type and i[0] != idx][:top_k]\n",
    "\n",
    "    # Empfohlene Produkte zurückgeben\n",
    "    recommended_products = df.loc[[i[0] for i in filtered_indices], ['product_name', 'product_url', 'product_type', 'price']]\n",
    "    recommended_products['cosine_similarity'] = [i[1] for i in filtered_indices]\n",
    "\n",
    "    return recommended_products\n",
    "\n",
    "# Test der erweiterten Empfehlungsfunktion mit Produkttyp-Filter\n",
    "print(enhanced_recommend_products_same_type(\"The Ordinary Natural Moisturising Factors + HA 30ml\", df, cosine_sim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Cosine Similarity der empfohlenen Produkte\n",
    "def plot_cosine_similarity(recommended_products):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='cosine_similarity', y='product_name', data=recommended_products)\n",
    "    plt.title('Cosine Similarity der empfohlenen Produkte')\n",
    "    plt.xlabel('Cosine Similarity')\n",
    "    plt.ylabel('Produktname')\n",
    "    plt.show()\n",
    "\n",
    "plot_cosine_similarity(recommended_products)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
